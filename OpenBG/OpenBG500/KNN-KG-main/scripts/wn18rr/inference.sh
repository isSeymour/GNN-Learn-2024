python main.py --gpus "2," --max_epochs 8  --num_workers 32 \
   --model_name_or_path  bert-base-uncased \
   --accumulate_grad_batches 1 \
   --model_class BertKGC \
   --batch_size 128 \
   --checkpoint your_model \
   --litmodel_class CombineEntityEmbeddingLitModel \
   --pretrain 0 \
   --bce 0 \
   --check_val_every_n_epoch 1 \
   --data_dir dataset/wn18rr \
   --eval_batch_size 128 \
   --knn_topk 64 \
   --knn_lambda 0.2 \
   --wandb \
   --max_seq_length 64 \
   --lr 3e-5
